{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7937464f",
   "metadata": {},
   "source": [
    "# RECOMMENDER SYSTEM SPOTIFY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f7401b",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/music-recommendation-system-using-machine-learning/#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b667ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ec829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load general utilities\n",
    "# ----------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import ast\n",
    "\n",
    "# Machine Learning Packages\n",
    "# ----------------------\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# ----------------------\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9227e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artists = pd.read_csv(\"artists.csv\")\n",
    "\n",
    "# Filter out rows where genres is \"[]\"\n",
    "df_artists = df_artists[df_artists['genres'] != \"[]\"]\n",
    "df_artists.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea92b80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the Excel file\n",
    "# df_music = pd.read_excel('tracks_converted.xlsx', engine='openpyxl')\n",
    "# df_music.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9afbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_music = pd.read_csv(\"tracks.csv\")\n",
    "df_music.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e9bc8e",
   "metadata": {},
   "source": [
    "#### Join Artist Genres info into Track on artist's ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7e5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, normalize the dataframes if not already done\n",
    "# Assuming the ids in df_music['id_artists'] are stored as strings\n",
    "df_music['id_artists'] = df_music['id_artists'].apply(ast.literal_eval)\n",
    "\n",
    "# Set the 'id' column in df_artists as the index for easy lookup\n",
    "df_artists.set_index('id', inplace=True)\n",
    "\n",
    "# Use the explode function to create individual rows for each artist id\n",
    "df_music_exploded = df_music.explode('id_artists')\n",
    "\n",
    "# Merge the exploded df_music with df_artists on the artist ids\n",
    "merged_df = df_music_exploded.merge(df_artists[['genres']], \n",
    "                                    left_on='id_artists', \n",
    "                                    right_index=True, \n",
    "                                    how='left')\n",
    "\n",
    "# Fill NaN with empty list\n",
    "merged_df['genres'] = merged_df['genres'].apply(lambda x: [] if pd.isnull(x) else ast.literal_eval(x))\n",
    "\n",
    "# Group by the original index of df_music and aggregate the genres\n",
    "final_genres = merged_df.groupby(merged_df.index)['genres'].agg(sum)\n",
    "\n",
    "# Ensure that genres in final_genres are unique\n",
    "final_genres = final_genres.apply(lambda x: list(set(x)))\n",
    "\n",
    "# Assign the aggregated genres back to the original df_music\n",
    "df_music['genres'] = final_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7761f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_music.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75c0857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modification to release date\n",
    "# Convert release_date to string type\n",
    "df_music['release_date'] = df_music['release_date'].str.split(' ').str[0]\n",
    "\n",
    "# Initialize new columns with NaN values\n",
    "df_music['release_year'] = pd.np.nan\n",
    "df_music['release_month'] = pd.np.nan\n",
    "df_music['release_day'] = pd.np.nan\n",
    "\n",
    "# Split and assign based on the length of the split\n",
    "for idx, date_str in enumerate(df_music['release_date']):\n",
    "    parts = date_str.split('-')\n",
    "    \n",
    "    if len(parts) == 1:\n",
    "        df_music.at[idx, 'release_year'] = parts[0]\n",
    "    elif len(parts) == 2:\n",
    "        df_music.at[idx, 'release_year'] = parts[0]\n",
    "        df_music.at[idx, 'release_month'] = parts[1]\n",
    "    elif len(parts) == 3:\n",
    "        df_music.at[idx, 'release_year'] = parts[0]\n",
    "        df_music.at[idx, 'release_month'] = parts[1]\n",
    "        df_music.at[idx, 'release_day'] = parts[2]\n",
    "\n",
    "# Convert the newly created columns to the appropriate data type\n",
    "df_music['release_year'] = df_music['release_year'].astype(int)\n",
    "df_music['release_month'] = df_music['release_month'].fillna(-1).astype(int)\n",
    "df_music['release_day'] = df_music['release_day'].fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e23316",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_music.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda24044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_music.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3372b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_music.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7938fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_music.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c149d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where have NaN values\n",
    "df_music.dropna(inplace = True)\n",
    "\n",
    "# Drop rows where 'release_month' or 'release_day' have a value of -1\n",
    "df_music = df_music[~((df_music['release_month'] == -1) | (df_music['release_day'] == -1) | (df_music['key'] == -1))]\n",
    "\n",
    "# Drop rows where genres is an empty list\n",
    "df_music = df_music[df_music['genres'].apply(lambda x: bool(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3ae424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_music = df_music.sort_values(by=['release_year','release_month','release_day'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1928fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_music.drop_duplicates(subset=['name'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf49cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_music.drop('release_date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b5f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_music.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4498b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by release_year and count\n",
    "yearly_counts = df_music.groupby('release_year').size()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(20,6))\n",
    "yearly_counts.plot(kind='bar')\n",
    "plt.title('Number of Pieces of Music Released Each Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Pieces')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c459645",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee1518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# One-hot encode the 'genres' column\n",
    "df_music_genres = df_music.join(pd.DataFrame(mlb.fit_transform(df_music.pop('genres')),\n",
    "                                             columns=mlb.classes_,\n",
    "                                             index=df_music.index))\n",
    "\n",
    "# Show the new dataframe with one-hot encoded genres\n",
    "df_music_genres.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b71ca7b",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cfb7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose song attributes for the recommendation engine\n",
    "recommendation_features = ['danceability', 'energy', 'key', 'loudness', 'mode',\n",
    "                           'speechiness', 'acousticness', 'instrumentalness',\n",
    "                           'liveness', 'valence', 'tempo', 'time_signature']\n",
    "\n",
    "# Select these features from the dataframe\n",
    "df_recommendation_features = df_music_genres[['id'] + recommendation_features + list(mlb.classes_)]\n",
    "\n",
    "# Show the feature set for the recommendation engine\n",
    "df_recommendation_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb5872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'followers' is a column in df_artists and it has been merged with df_music\n",
    "# Feature Engineering for the popularity prediction model\n",
    "popularity_features = [\n",
    "    'followers', 'popularity', 'danceability', 'energy', 'key', 'loudness', \n",
    "    'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', \n",
    "    'valence', 'tempo', 'time_signature'\n",
    "]\n",
    "\n",
    "# Explode 'id_artists' column to have one artist ID per row\n",
    "df_music_exploded = df_music.explode('id_artists')\n",
    "\n",
    "# Merge the 'followers' column from df_artists into df_music_exploded\n",
    "df_music_with_followers = df_music_exploded.merge(df_artists[['followers']], left_on='id_artists', right_index=True, how='left')\n",
    "\n",
    "# Since we have exploded the df_music, there might be duplicated tracks with different artist IDs,\n",
    "# we need to drop these duplicates to revert to the original track structure\n",
    "# We can do this by dropping duplicates based on the track's 'id'\n",
    "df_music_with_followers = df_music_with_followers.drop_duplicates(subset='id')\n",
    "\n",
    "# Now that 'followers' is part of df_music, we can select the popularity features\n",
    "df_popularity_features = df_music_with_followers[popularity_features]\n",
    "\n",
    "# Show the feature set for the popularity prediction model\n",
    "df_popularity_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfec7b8",
   "metadata": {},
   "source": [
    "## Recommender Model and Popularity Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4cf77d",
   "metadata": {},
   "source": [
    "### Step 1: Split the Data for Popularity Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffab99b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the features and target variable\n",
    "X = df_popularity_features.drop('popularity', axis=1)\n",
    "y = df_popularity_features['popularity']\n",
    "\n",
    "# Splitting the data into train+validation and test sets (80-20)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitting the train+validation into train and validation sets (90-10)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_temp, y_temp, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be54976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for infinite values and replace them with NaN\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "y_train = y_train.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Handle missing values (which now includes the previously infinite values)\n",
    "X_train = X_train.fillna(X_train.mean())\n",
    "y_train = y_train.fillna(y_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad58a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values with the median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "X_validation_imputed = imputer.transform(X_validation)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "X_validation_scaled = scaler.transform(X_validation_imputed)  \n",
    "\n",
    "# Check if there are any remaining non-finite values\n",
    "if not np.all(np.isfinite(X_train_scaled)):\n",
    "    raise ValueError(\"All values in X_train_scaled must be finite.\")\n",
    "if not np.all(np.isfinite(X_test_scaled)):\n",
    "    raise ValueError(\"All values in X_test_scaled must be finite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47dc641",
   "metadata": {},
   "source": [
    "### Step 2: Train Multiple ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6331b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Define the parameter grid for Gradient Boosting\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Define the parameter grid for Support Vector Regression\n",
    "svr_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "# Create the models\n",
    "models = {\n",
    "    'RandomForestRegressor': (RandomForestRegressor(random_state=42), rf_param_grid),\n",
    "    'GradientBoostingRegressor': (GradientBoostingRegressor(random_state=42), gb_param_grid),\n",
    "    'SVR': (SVR(), svr_param_grid)\n",
    "}\n",
    "\n",
    "# Dictionary to store the best models and best parameters for each algorithm\n",
    "best_models = {}\n",
    "best_params = {}\n",
    "best_scores = {}\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Store the best model, parameters, and score\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "    best_params[model_name] = grid_search.best_params_\n",
    "    best_scores[model_name] = -grid_search.best_score_\n",
    "    \n",
    "    # Validate the best model\n",
    "    y_validation_predictions = best_models[model_name].predict(X_validation_scaled)\n",
    "    rmse = mean_squared_error(y_validation, y_validation_predictions, squared=False)\n",
    "    print(f\"Validation RMSE for {model_name}: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed0f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model\n",
    "# rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# # Fit the model on the training data\n",
    "# rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058acbcd",
   "metadata": {},
   "source": [
    "### Step 4: Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400e83a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best model overall based on validation RMSE\n",
    "best_model_name = min(best_scores, key=best_scores.get)\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "print(f\"The best model is {best_model_name} with a validation RMSE of {best_scores[best_model_name]}\")\n",
    "\n",
    "# Save the best model to a file\n",
    "joblib.dump(best_model, 'best_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055660bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # When making predictions, make sure to use the scaled validation data\n",
    "# y_validation_predictions = rf_model.predict(X_validation_scaled)\n",
    "\n",
    "# # Now calculate the RMSE using the predictions and the actual y_validation values\n",
    "# rmse = mean_squared_error(y_validation, y_validation_predictions, squared=False)\n",
    "# print(f\"Validation RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a614903",
   "metadata": {},
   "source": [
    "### Step 4: Develop the Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b24bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_csr = df_recommendation_features.drop('id', axis=1).sparse.to_coo().tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a89dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recommend songs based on a given song ID\n",
    "def recommend_songs(song_id, df, csr_data, number_of_songs=5):\n",
    "    \n",
    "    # Find the row of the given song ID\n",
    "    index = df.index[df['id'] == song_id].tolist()[0]\n",
    "\n",
    "    # Calculate similarity scores for the specific song against all others\n",
    "    similarity_scores = cosine_similarity(csr_data[index:index+1], csr_data).flatten()\n",
    "\n",
    "    # Get the indices of the top songs, skipping the first one since it's the song itself\n",
    "    top_indices = similarity_scores.argsort()[-number_of_songs-1:-1][::-1]\n",
    "\n",
    "    # Get the song indices\n",
    "    song_indices = df.iloc[top_indices].index\n",
    "\n",
    "    # Return the most similar songs\n",
    "    return df['id'].iloc[song_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c44964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to recommend songs based on a given song ID\n",
    "# def recommend_songs(song_id, df, csr_data, number_of_songs=5):\n",
    "#     # Find the row of the given song ID\n",
    "#     index = df.index[df['id'] == song_id].tolist()[0]\n",
    "\n",
    "#     # Calculate similarity scores for the specific song against all others\n",
    "#     similarity_scores = cosine_similarity(csr_data[index], csr_data).flatten()\n",
    "\n",
    "#     # Get the indices of the top songs, skipping the first one since it's the song itself\n",
    "#     top_indices = similarity_scores.argsort()[-number_of_songs-1:-1][::-1]\n",
    "\n",
    "#     # Get the song indices\n",
    "#     song_indices = df.iloc[top_indices].index\n",
    "\n",
    "#     # Return the most similar songs\n",
    "#     return df['id'].iloc[song_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15123cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "recommended_song_ids = recommend_songs(some_song_id, df_recommendation_features, csr_data, 5)\n",
    "print(song_recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
